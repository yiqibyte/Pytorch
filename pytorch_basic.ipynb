{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 14 05:57:08 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   38C    P8     9W /  70W |      5MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from torch.backends import cudnn\n",
    "\n",
    "x = torch.normal(0, 1, (1, 2))\n",
    "x.requires_grad = True\n",
    "print(cudnn.is_acceptable(x))\n",
    "\n",
    "x = x.cuda()\n",
    "print(cudnn.is_acceptable(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 27.93531894683838\n",
      "GPU without cuDNN: 1.4835753440856934\n",
      "GPU with cuDNN: 1.196150302886963\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x_cpu = torch.randn(64, 3, 224, 224)\n",
    "conv_cpu = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "\n",
    "# CPU 测试\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y = conv_cpu(x_cpu)\n",
    "print(\"CPU:\", time.time() - start)\n",
    "\n",
    "# 准备 GPU 输入\n",
    "x_gpu = x_cpu.cuda()\n",
    "\n",
    "# GPU + cuDNN 关闭\n",
    "torch.backends.cudnn.enabled = False\n",
    "conv_gpu_nocudnn = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1).cuda()\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y = conv_gpu_nocudnn(x_gpu)\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU without cuDNN:\", time.time() - start)\n",
    "\n",
    "# GPU + cuDNN 开启\n",
    "torch.backends.cudnn.enabled = True\n",
    "conv_gpu_cudnn = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1).cuda()\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    y = conv_gpu_cudnn(x_gpu)\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU with cuDNN:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 原始张量：shape = (2, 3)\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"原始张量:\\n\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reshape 到 (3, 2):\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "view 展平为一维:\n",
      " tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. reshape / view：改变形状，不改变数据内容\n",
    "x_reshaped = x.reshape(3, 2)  # 推荐写法\n",
    "print(\"\\nreshape 到 (3, 2):\\n\", x_reshaped)\n",
    "\n",
    "x_view = x.view(-1)  # 展平成一维\n",
    "print(\"\\nview 展平为一维:\\n\", x_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "unsqueeze 添加第0维 (1,3):\n",
      " tensor([[1, 2, 3]])\n",
      "unsqueeze 添加第1维 (3,1):\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 2. unsqueeze：增加维度\n",
    "x1d = torch.tensor([1, 2, 3])  # shape=(3,)\n",
    "\n",
    "x_unsq0 = x1d.unsqueeze(0)  # shape=(1, 3)\n",
    "x_unsq1 = x1d.unsqueeze(1)  # shape=(3, 1)\n",
    "\n",
    "print(\"\\nunsqueeze 添加第0维 (1,3):\\n\", x_unsq0)\n",
    "print(\"unsqueeze 添加第1维 (3,1):\\n\", x_unsq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "squeeze 去除尺寸为1的维度:\n",
      " tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 3. squeeze：去除尺寸为1的维度\n",
    "x_squeeze_input = torch.tensor([[[1], [2], [3]]])  # shape=(1,3,1)\n",
    "x_squeezed = x_squeeze_input.squeeze()  # shape=(3,)\n",
    "print(\"\\nsqueeze 去除尺寸为1的维度:\\n\", x_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transpose 交换维度:\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 4. transpose：交换两个维度\n",
    "x_transposed = x.transpose(0, 1)  # 交换第0维和第1维：shape=(3,2)\n",
    "print(\"\\ntranspose 交换维度:\\n\", x_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "permute 重排维度 (2,3,4) -> (4,2,3):\n",
      " torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 5. permute：对所有维度重新排序\n",
    "x3d = torch.randn(2, 3, 4)  # shape=(2,3,4)\n",
    "x_permuted = x3d.permute(2, 0, 1)  # shape=(4,2,3)\n",
    "print(\"\\npermute 重排维度 (2,3,4) -> (4,2,3):\\n\", x_permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "flatten 展平为一维:\n",
      " tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 6. flatten：展平部分维度\n",
    "x2 = torch.tensor([[1, 2], [3, 4]])\n",
    "x_flattened = torch.flatten(x2)  # shape=(4,)\n",
    "print(\"\\nflatten 展平为一维:\\n\", x_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resize_ 原地改变形状 (注意不推荐):\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# ✅ 7. resize_：**原地操作**，可能破坏原数据\n",
    "x_resize = torch.tensor([1, 2, 3, 4])\n",
    "x_resize.resize_(2, 2)\n",
    "print(\"\\nresize_ 原地改变形状 (注意不推荐):\\n\", x_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6535, 3.0759, 2.6140],\n",
       "        [3.4554, 1.9575, 3.6414]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.normal(0, 1, (2, 3))\n",
    "b = torch.full_like(a, 7.)\n",
    "# torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None)\n",
    "input = torch.tensor(3.)\n",
    "torch.addcdiv(input, a, b, value=3)\n",
    "# torch.addcmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8086, -0.1770,  0.9006],\n",
       "        [-1.0626,  2.4325, -1.4965]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.neg(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4325)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(a, b, p=torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ge(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.le(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gt(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.lt(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8086,  0.1770, -0.9006],\n",
      "        [ 1.0626, -2.4325,  1.4965]])\n",
      "tensor([[ 0.1770, -0.8086],\n",
      "        [ 1.4965,  1.0626]])\n",
      "tensor([[1, 0],\n",
      "        [2, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(torch.topk(a, 2, dim=1)[0])\n",
    "print(torch.topk(a, 2, dim=1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n",
      "tensor([2., 4., 6.])\n",
      "tensor([ 4., 10., 18.])\n",
      "tensor([ 4., 10., 18.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# 与标量相乘\n",
    "print(a * 2)                  # tensor([2.0, 4.0, 6.0])\n",
    "print(torch.mul(a, 2))        # 同上\n",
    "\n",
    "# 逐元素乘法（element-wise）\n",
    "print(a * b)                  # tensor([4.0, 10.0, 18.0])\n",
    "print(torch.mul(a, b))        # 同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# 推荐方式：使用 @ 运算符\n",
    "print(A @ B)\n",
    "\n",
    "# 使用 matmul（支持 1D/2D/高维）\n",
    "print(torch.matmul(A, B))\n",
    "\n",
    "# 使用 mm（只支持 2D）\n",
    "print(torch.mm(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.2595, -0.0759,  2.7515,  1.0268],\n",
      "         [-3.1586, -1.1257,  1.0849, -1.8221]],\n",
      "\n",
      "        [[-0.8149, -1.1841,  8.0182,  2.7357],\n",
      "         [ 0.0549, -0.0522, -1.0161,  0.1989]],\n",
      "\n",
      "        [[ 2.0990,  0.3018, -0.4382, -0.5291],\n",
      "         [-6.0966, -2.6868,  0.1488,  1.2637]],\n",
      "\n",
      "        [[-0.2429,  0.0813, -0.1786,  1.6716],\n",
      "         [-2.3099,  0.3499, -1.6873, -0.9331]],\n",
      "\n",
      "        [[-4.1601, -1.7306, -0.1414,  3.4027],\n",
      "         [ 0.0715, -0.5991,  0.0747, -0.8925]],\n",
      "\n",
      "        [[-0.7883,  2.3012,  1.3500,  3.2958],\n",
      "         [-0.3670,  1.7750,  1.6516,  0.2526]],\n",
      "\n",
      "        [[-0.1083, -0.9768, -3.1181,  1.4984],\n",
      "         [ 1.1062, -0.0102,  0.1982, -0.7728]],\n",
      "\n",
      "        [[-0.4367,  1.6546, -2.4659, -2.2413],\n",
      "         [-0.6002,  1.1254, -0.4258, -0.2553]],\n",
      "\n",
      "        [[ 2.0478,  2.0182,  3.0777,  1.5817],\n",
      "         [ 0.3768,  1.6207, -0.1454,  0.6417]],\n",
      "\n",
      "        [[ 0.3362,  1.8548, -1.7134,  0.4524],\n",
      "         [-0.5935, -0.4444,  0.6190,  0.0428]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(10, 2, 3)\n",
    "B = torch.randn(10, 3, 4)\n",
    "\n",
    "# 批量矩阵乘法：输出形状为 (10, 2, 4)\n",
    "C = torch.bmm(A, B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# 1D 向量点积：结果是标量\n",
    "print(torch.dot(x, y))  # 32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  5.],\n",
      "        [ 8., 10.],\n",
      "        [12., 15.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0])\n",
    "\n",
    "# outer product：3x2 矩阵\n",
    "print(torch.outer(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  5.],\n",
      "        [ 8., 10.],\n",
      "        [12., 15.]])\n"
     ]
    }
   ],
   "source": [
    "a.unsqueeze_(1)\n",
    "b.unsqueeze_(0)\n",
    "print(torch.mm(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 与 NumPy 函数对照表\n",
    "\n",
    "| 操作类别       | NumPy                                      | PyTorch                                       |\n",
    "|----------------|---------------------------------------------|-----------------------------------------------|\n",
    "| 数据类型       | `np.ndarray`                                | `torch.Tensor`                                |\n",
    "|                | `np.float32`                                | `torch.float32`, `torch.float`                |\n",
    "|                | `np.float64`                                | `torch.float64`, `torch.double`               |\n",
    "|                | `np.int64`                                  | `torch.int64`, `torch.long`                   |\n",
    "| 构建张量       | `np.array([3.2, 4.3], dtype=np.float16)`     | `torch.tensor([3.2, 4.3], dtype=torch.float16)` |\n",
    "|                | `x.copy()`                                  | `x.clone()`                                   |\n",
    "| 拼接           | `np.concatenate`                            | `torch.cat`                                   |\n",
    "| 线性代数       | `np.dot`                                    | `torch.mm`                                    |\n",
    "| 属性           | `x.ndim`                                    | `x.dim()`                                     |\n",
    "|                | `x.size`                                    | `x.nelement()`                                |\n",
    "| 形状操作       | `x.reshape`                                 | `x.reshape()`, `x.view()`                     |\n",
    "|                | `x.flatten()`                               | `x.view(-1)`                                  |\n",
    "| 类型转换       | `np.floor(x)`                               | `torch.floor(x)`, `x.floor()`                 |\n",
    "| 比较运算       | `np.less(x, y)`                             | `x.lt(y)`                                     |\n",
    "|                | `np.less_equal(x, y)` / `np.greater(x, y)` | `x.le(y)` / `x.gt(y)`                         |\n",
    "|                | `np.equal(x, y)` / `np.not_equal(x, y)`    | `x.eq(y)` / `x.ne(y)`                         |\n",
    "| 随机种子       | `np.random.seed(0)`                         | `torch.manual_seed(0)`                        |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
